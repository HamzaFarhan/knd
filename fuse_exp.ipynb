{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal\n",
    "\n",
    "import logfire\n",
    "from dotenv import load_dotenv\n",
    "from langfuse import Langfuse\n",
    "from langfuse.decorators import langfuse_context\n",
    "from pydantic_ai import Agent\n",
    "\n",
    "load_dotenv(\"../smol/.env\")\n",
    "\n",
    "logfire.configure(send_to_logfire=False)\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "langfuse = Langfuse()\n",
    "dataset_name = \"football_facts\"\n",
    "langfuse.create_dataset(name=dataset_name)\n",
    "\n",
    "items = [\n",
    "    {\"input\": \"did messi win the fifa world cup?\", \"expected_output\": \"yes\"},\n",
    "    {\"input\": \"did ronaldo win the fifa world cup?\", \"expected_output\": \"yes\"},\n",
    "]\n",
    "\n",
    "# for item in items:\n",
    "#     langfuse.create_dataset_item(\n",
    "#         dataset_name=\"football_facts\", input=item[\"input\"], expected_output=item[\"expected_output\"]\n",
    "#     )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = Agent(\n",
    "    model=\"google-gla:gemini-1.5-flash\",\n",
    "    name=\"football_expert\",\n",
    "    system_prompt=\"You are a football(soccer) expert\",\n",
    "    instrument=True,\n",
    "    result_type=Literal[\"yes\", \"no\"],  # type: ignore\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_evaluation(output, expected_output):\n",
    "    return output == expected_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def run_experiment(experiment_name):\n",
    "    dataset = langfuse.get_dataset(dataset_name)\n",
    "\n",
    "    for item in dataset.items:\n",
    "        with logfire.span(experiment_name) as span:\n",
    "            trace_id = span.get_span_context().trace_id\n",
    "            trace_id = f\"{trace_id:032x}\"\n",
    "            print(trace_id)\n",
    "            with item.observe(run_name=experiment_name, trace_id=trace_id) as _:\n",
    "                output = await agent.run(item.input)\n",
    "                langfuse.score(\n",
    "                    trace_id=trace_id,\n",
    "                    name=\"exact_match\",\n",
    "                    value=simple_evaluation(output.data, item.expected_output),\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name = \"football_expert_run_1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15:59:38.084 football_expert_run_1\n",
      "0195767bc664429c1bcd0bd97f7e68ad\n",
      "15:59:38.088   football_expert run\n",
      "15:59:38.090     preparing model request params\n",
      "15:59:38.092     chat gemini-1.5-flash\n",
      "15:59:41.012 football_expert_run_1\n",
      "0195767bd1d448b4130a56614da8fddb\n",
      "15:59:41.013   football_expert run\n",
      "15:59:41.014     preparing model request params\n",
      "15:59:41.014     chat gemini-1.5-flash\n"
     ]
    }
   ],
   "source": [
    "await run_experiment(experiment_name=experiment_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "langfuse_context.flush()\n",
    "langfuse.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_runs = langfuse.get_dataset_runs(dataset_name=dataset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "run = langfuse.get_dataset_run(dataset_name=dataset_name, dataset_run_name=experiment_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': [{'id': 'cm80e486p03v0ad0643h8qw3n',\n",
       "   'name': 'football_expert_run_1',\n",
       "   'description': None,\n",
       "   'metadata': None,\n",
       "   'datasetId': 'cm809dde0042pad07jzu49ikf',\n",
       "   'datasetName': 'football_facts',\n",
       "   'createdAt': datetime.datetime(2025, 3, 8, 15, 59, 40, 658000, tzinfo=datetime.timezone.utc),\n",
       "   'updatedAt': datetime.datetime(2025, 3, 8, 15, 59, 40, 658000, tzinfo=datetime.timezone.utc)}],\n",
       " 'meta': {'page': 1, 'limit': 50, 'totalItems': 1, 'totalPages': 1}}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_runs.dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'cm80e486p03v0ad0643h8qw3n',\n",
       " 'name': 'football_expert_run_1',\n",
       " 'datasetId': 'cm809dde0042pad07jzu49ikf',\n",
       " 'datasetName': 'football_facts',\n",
       " 'createdAt': datetime.datetime(2025, 3, 8, 15, 59, 40, 658000, tzinfo=datetime.timezone.utc),\n",
       " 'updatedAt': datetime.datetime(2025, 3, 8, 15, 59, 40, 658000, tzinfo=datetime.timezone.utc),\n",
       " 'datasetRunItems': [{'id': 'cm80e486x03v2ad06lzny8t2h',\n",
       "   'datasetRunId': 'cm80e486p03v0ad0643h8qw3n',\n",
       "   'datasetRunName': 'football_expert_run_1',\n",
       "   'datasetItemId': '7ec945c3-57a9-408f-8a5b-46ab0e6b26f3',\n",
       "   'traceId': '0195767bc664429c1bcd0bd97f7e68ad',\n",
       "   'observationId': None,\n",
       "   'createdAt': datetime.datetime(2025, 3, 8, 15, 59, 40, 665000, tzinfo=datetime.timezone.utc),\n",
       "   'updatedAt': datetime.datetime(2025, 3, 8, 15, 59, 40, 665000, tzinfo=datetime.timezone.utc)},\n",
       "  {'id': 'cm80e49ct03ydad06er9ao723',\n",
       "   'datasetRunId': 'cm80e486p03v0ad0643h8qw3n',\n",
       "   'datasetRunName': 'football_expert_run_1',\n",
       "   'datasetItemId': 'fd52e28e-8e6f-49c0-8e6b-bd57869f0e8d',\n",
       "   'traceId': '0195767bd1d448b4130a56614da8fddb',\n",
       "   'observationId': None,\n",
       "   'createdAt': datetime.datetime(2025, 3, 8, 15, 59, 42, 174000, tzinfo=datetime.timezone.utc),\n",
       "   'updatedAt': datetime.datetime(2025, 3, 8, 15, 59, 42, 174000, tzinfo=datetime.timezone.utc)}],\n",
       " 'description': None,\n",
       " 'metadata': None}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run.dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Doesn't it depend on the flow/use case?\n",
    "If you have 4 tasks that take 5 minutes each but need to be done in sequence:\n",
    "- Agent A does tasks 1 -> 2 (10 minutes)\n",
    "- Agent A \"hands-off\" to Agent B\n",
    "- Agent B does tasks 3 -> 4 (10 minutes)\n",
    "It will take 20 minutes.\n",
    "They can't run concurrently because each tasks input depends on the output of the previous task."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
