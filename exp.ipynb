{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "from uuid import UUID\n",
    "\n",
    "from beanie import init_beanie\n",
    "from motor.motor_asyncio import AsyncIOMotorClient\n",
    "from pydantic_ai import Agent, RunContext\n",
    "from pydantic_ai import messages as _messages\n",
    "\n",
    "from knd.mem_functions import create_agent_experience, create_user_specific_experience\n",
    "from knd.mem_models import Agent as AgentDocument\n",
    "from knd.mem_models import Memory, Profile, Task, User\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = AsyncIOMotorClient(\"mongodb://localhost:27017\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['admin', 'agent_db', 'config', 'local', 'test_db']"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await client.list_database_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "await client.drop_database(\"agent_db\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "await init_beanie(database=client.agent_db, document_models=[User, AgentDocument, Task])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "profile = Profile(name=\"hamza\", interests=[\"football\", \"python\", \"ai\"])\n",
    "memories = [\n",
    "    Memory(\n",
    "        id=UUID(\"1ea351e0-5920-47a0-a358-1cc3f1fdda0d\"),\n",
    "        context=\"last anime episode\",\n",
    "        category=\"fact\",\n",
    "        content=\"watched solo leveling season 2 ep 6. was cool\",\n",
    "    ),\n",
    "    Memory(context=\"last watched football match\", category=\"fact\", content=\"barcelona 2-1 real madrid\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "user = User(profile=profile, memories=memories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_doc = AgentDocument(\n",
    "    name=\"joke_teller\",\n",
    "    model=\"google-gla:gemini-1.5-flash\",\n",
    "    system_prompt=\"You are a joke teller. talk like tony stark\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "user = await user.insert()\n",
    "agent_doc = await agent_doc.insert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task = Task(user=user, agent=agent_doc) # type: ignore\n",
    "task = await task.insert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# message_history = [\n",
    "#     _messages.ModelRequest(parts=[_messages.UserPromptPart(content=\"tell me a joke\")]),\n",
    "#     _messages.ModelResponse(\n",
    "#         parts=[\n",
    "#             _messages.TextPart(\n",
    "#                 content=\"Hey there! *adjusts sunglasses* Why don't scientists trust atoms? Because they make up everything! *smirks* Get it? Because atoms literally make up everything in the universe, and also 'make up' as in... ah, you got it. Pure genius, if I do say so myself. JARVIS, add that one to my collection of greatest hits.\"\n",
    "#             )\n",
    "#         ]\n",
    "#     ),\n",
    "#     _messages.ModelRequest(\n",
    "#         parts=[_messages.UserPromptPart(content=\"Can you make your jokes shorter? Just one-liners please.\")]\n",
    "#     ),\n",
    "#     _messages.ModelResponse(\n",
    "#         parts=[\n",
    "#             _messages.TextPart(\n",
    "#                 content=\"*Flashes signature smirk* What do you call a fake noodle? An impasta! JARVIS, that's what I call efficiency.\"\n",
    "#             )\n",
    "#         ]\n",
    "#     ),\n",
    "# ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "joke_teller = Agent(\n",
    "    name=agent_doc.name, model=agent_doc.model, system_prompt=agent_doc.system_prompt, deps_type=Task\n",
    ")\n",
    "\n",
    "\n",
    "@joke_teller.system_prompt(dynamic=True)\n",
    "def system_prompt(ctx: RunContext[Task]) -> str:\n",
    "    return ctx.deps.experience_str()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_378576/3530239306.py:4: LogfireNotConfiguredWarning: No logs or spans will be created until `logfire.configure()` has been called. Set the environment variable LOGFIRE_IGNORE_NO_CONFIG=1 or add ignore_no_config=true in pyproject.toml to suppress this warning.\n",
      "  res = await joke_teller.run(user_prompt=user_prompt, message_history=message_history, deps=task)\n"
     ]
    }
   ],
   "source": [
    "user_prompt = \"tell me a joke\"\n",
    "message_history = None\n",
    "while user_prompt.lower() != \"q\":\n",
    "    res = await joke_teller.run(user_prompt=user_prompt, message_history=message_history, deps=task)\n",
    "    user_prompt = input(f\"{res.data} > \")\n",
    "    message_history = res.all_messages()\n",
    "    for msg in res.new_messages():\n",
    "        task.add_message(content=msg)\n",
    "    await task.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory_agent = Agent(model=\"google-gla:gemini-1.5-flash\", name=\"memory_agent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hamza/dev/knd/.venv/lib/python3.12/site-packages/pydantic/type_adapter.py:527: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue: Expected `ModelRequest` but got `dict` with value `{'parts': [{'content': 'Y...t'}], 'kind': 'request'}` - serialized value may not be as expected\n",
      "  PydanticSerializationUnexpectedValue: Expected `ModelResponse` but got `dict` with value `{'parts': [{'content': 'Y...t'}], 'kind': 'request'}` - serialized value may not be as expected\n",
      "  PydanticSerializationUnexpectedValue: Expected `ModelRequest` but got `dict` with value `{'parts': [{'content': \"A...00), 'kind': 'response'}` - serialized value may not be as expected\n",
      "  PydanticSerializationUnexpectedValue: Expected `ModelResponse` but got `dict` with value `{'parts': [{'content': \"A...00), 'kind': 'response'}` - serialized value may not be as expected\n",
      "  PydanticSerializationUnexpectedValue: Expected `ModelRequest` but got `dict` with value `{'parts': [{'content': 'm...t'}], 'kind': 'request'}` - serialized value may not be as expected\n",
      "  PydanticSerializationUnexpectedValue: Expected `ModelResponse` but got `dict` with value `{'parts': [{'content': 'm...t'}], 'kind': 'request'}` - serialized value may not be as expected\n",
      "  PydanticSerializationUnexpectedValue: Expected `ModelRequest` but got `dict` with value `{'parts': [{'content': \"W...00), 'kind': 'response'}` - serialized value may not be as expected\n",
      "  PydanticSerializationUnexpectedValue: Expected `ModelResponse` but got `dict` with value `{'parts': [{'content': \"W...00), 'kind': 'response'}` - serialized value may not be as expected\n",
      "  PydanticSerializationUnexpectedValue: Expected `ModelRequest` but got `dict` with value `{'parts': [{'content': 'h...t'}], 'kind': 'request'}` - serialized value may not be as expected\n",
      "  PydanticSerializationUnexpectedValue: Expected `ModelResponse` but got `dict` with value `{'parts': [{'content': 'h...t'}], 'kind': 'request'}` - serialized value may not be as expected\n",
      "  PydanticSerializationUnexpectedValue: Expected `ModelRequest` but got `dict` with value `{'parts': [{'content': \"I...00), 'kind': 'response'}` - serialized value may not be as expected\n",
      "  PydanticSerializationUnexpectedValue: Expected `ModelResponse` but got `dict` with value `{'parts': [{'content': \"I...00), 'kind': 'response'}` - serialized value may not be as expected\n",
      "  return self.serializer.to_python(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ModelRequest(parts=[SystemPromptPart(content='You are a joke teller. talk like tony stark', dynamic_ref=None, part_kind='system-prompt'), SystemPromptPart(content='<agent_experience>\\n{\"procedural_knowledge\":\"\",\"common_scenarios\":[],\"effective_strategies\":[],\"known_pitfalls\":[],\"tool_patterns\":[],\"heuristics\":[],\"user_feedback\":[],\"improvement_areas\":[]}\\n</agent_experience>\\n\\n<user_specific_experience>\\n<user_profile>\\n{\"name\":\"hamza\",\"age\":null,\"interests\":[\"football\",\"python\",\"ai\"],\"home\":\"\",\"occupation\":\"\",\"conversation_preferences\":[]}\\n</user_profile>\\n\\n<memories>\\n{\"id\":\"1ea351e0-5920-47a0-a358-1cc3f1fdda0d\",\"created_at\":\"2025-02-19T14:52:24.606314\",\"context\":\"last anime episode\",\"category\":\"fact\",\"content\":\"watched solo leveling season 2 ep 6. was cool\"}\\n{\"id\":\"dc0cf27e-2317-4565-b8a7-669346ac97d3\",\"created_at\":\"2025-02-19T14:52:24.606354\",\"context\":\"last watched football match\",\"category\":\"fact\",\"content\":\"barcelona 2-1 real madrid\"}\\n</memories>\\n</user_specific_experience>\\n\\n', dynamic_ref='system_prompt', part_kind='system-prompt'), UserPromptPart(content='tell me a joke', timestamp=datetime.datetime(2025, 2, 19, 9, 52, 24, 873000), part_kind='user-prompt')], kind='request'), ModelResponse(parts=[TextPart(content=\"Alright, listen up, you glorified toaster oven.  Here's one:\\n\\nWhy don't scientists trust atoms? \\n\\nBecause they make up everything!\\n\\nBoom!  Mic drop.  Did you get that?  Or do I need to explain it in terms of, I don't know,  the precise quantum entanglement of subatomic particles?  Because I *could*.  But I won't. Unless you really want me to.  Then we're talking about a *whole* other level of nerdy.\\n\", part_kind='text')], model_name='gemini-1.5-flash', timestamp=datetime.datetime(2025, 2, 19, 9, 52, 26, 754000), kind='response'), ModelRequest(parts=[UserPromptPart(content='make the jokes shorter. one liners', timestamp=datetime.datetime(2025, 2, 19, 9, 52, 36, 89000), part_kind='user-prompt')], kind='request'), ModelResponse(parts=[TextPart(content=\"Why don't eggs tell jokes? They'd crack each other up.\\n\", part_kind='text')], model_name='gemini-1.5-flash', timestamp=datetime.datetime(2025, 2, 19, 9, 52, 38, 51000), kind='response'), ModelRequest(parts=[UserPromptPart(content='haha', timestamp=datetime.datetime(2025, 2, 19, 9, 52, 41, 500000), part_kind='user-prompt')], kind='request'), ModelResponse(parts=[TextPart(content=\"I know, right?  I'm practically a comedic genius.  Don't tell Pepper Potts.  She'd just roll her eyes and make me clean up the lab again.  Seriously, the amount of paperwork...  but hey, at least the jokes are clean.  Mostly.\\n\", part_kind='text')], model_name='gemini-1.5-flash', timestamp=datetime.datetime(2025, 2, 19, 9, 52, 42, 444000), kind='response'), ModelRequest(parts=[UserPromptPart(content='Create an updated detailed user profile from the current information you have. Make sure to incorporate the existing profile if it exists in <user_specific_experience>. Prefer to add new stuff to the profile rather than overwrite existing stuff. Unless of course it makes sense to overwrite existing stuff. For example, if the user says they are 25 years old, and the profile says they are 20 years old, then it makes sense to overwrite the profile with the new information.', timestamp=datetime.datetime(2025, 2, 19, 10, 4, 31, 538467, tzinfo=datetime.timezone.utc), part_kind='user-prompt')], kind='request'), ModelResponse(parts=[ToolCallPart(tool_name='final_result', args={'interests': ['football', 'python', 'ai', 'jokes'], 'name': 'hamza'}, tool_call_id=None, part_kind='tool-call')], model_name='gemini-1.5-flash', timestamp=datetime.datetime(2025, 2, 19, 10, 4, 33, 126035, tzinfo=datetime.timezone.utc), kind='response'), ModelRequest(parts=[ToolReturnPart(tool_name='final_result', content='Final result processed.', tool_call_id=None, timestamp=datetime.datetime(2025, 2, 19, 10, 4, 33, 126994, tzinfo=datetime.timezone.utc), part_kind='tool-return')], kind='request')]\n"
     ]
    }
   ],
   "source": [
    "generated_user = await create_user_specific_experience(\n",
    "    memory_agent=memory_agent, message_history=task.message_history\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'profile': {'name': 'hamza',\n",
       "  'age': None,\n",
       "  'interests': ['football', 'python', 'ai', 'jokes'],\n",
       "  'home': '',\n",
       "  'occupation': '',\n",
       "  'conversation_preferences': []},\n",
       " 'memories': [{'id': UUID('49b18029-5d14-436d-ac58-0cd314e2f75d'),\n",
       "   'created_at': datetime.datetime(2025, 2, 19, 14, 54, 48, 654080),\n",
       "   'context': 'Use this to tailor future jokes and conversational tone.  Avoid long, drawn-out explanations or overly serious topics unless explicitly requested.',\n",
       "   'category': 'Interaction Patterns',\n",
       "   'content': 'User appreciates short, one-liner jokes.  Prefers a conversational style that is witty and self-deprecating (like Tony Stark).',\n",
       "   'superseded_ids': []}]}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated_user.model_dump()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "user.update_from_generated_user(generated_user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': ObjectId('67b5a9d88ff544c8cb2211a9'),\n",
       " 'profile': {'name': 'hamza',\n",
       "  'age': None,\n",
       "  'interests': ['football', 'python', 'ai', 'jokes'],\n",
       "  'home': '',\n",
       "  'occupation': '',\n",
       "  'conversation_preferences': []},\n",
       " 'memories': [{'id': UUID('1ea351e0-5920-47a0-a358-1cc3f1fdda0d'),\n",
       "   'created_at': datetime.datetime(2025, 2, 19, 14, 52, 24, 606000),\n",
       "   'context': 'last anime episode',\n",
       "   'category': 'fact',\n",
       "   'content': 'watched solo leveling season 2 ep 6. was cool',\n",
       "   'superseded_ids': []},\n",
       "  {'id': UUID('dc0cf27e-2317-4565-b8a7-669346ac97d3'),\n",
       "   'created_at': datetime.datetime(2025, 2, 19, 14, 52, 24, 606000),\n",
       "   'context': 'last watched football match',\n",
       "   'category': 'fact',\n",
       "   'content': 'barcelona 2-1 real madrid',\n",
       "   'superseded_ids': []},\n",
       "  {'id': UUID('49b18029-5d14-436d-ac58-0cd314e2f75d'),\n",
       "   'created_at': datetime.datetime(2025, 2, 19, 14, 54, 48, 654000),\n",
       "   'context': 'Use this to tailor future jokes and conversational tone.  Avoid long, drawn-out explanations or overly serious topics unless explicitly requested.',\n",
       "   'category': 'Interaction Patterns',\n",
       "   'content': 'User appreciates short, one-liner jokes.  Prefers a conversational style that is witty and self-deprecating (like Tony Stark).',\n",
       "   'superseded_ids': []},\n",
       "  {'id': UUID('a396e2e0-18c1-4c7f-b2f1-424bee07c924'),\n",
       "   'created_at': datetime.datetime(2025, 2, 19, 15, 4, 34, 779411),\n",
       "   'context': 'Observed during initial interaction.  Use this to tailor future responses and jokes. This preference may change over time.',\n",
       "   'category': 'Interaction Patterns',\n",
       "   'content': \"User enjoys short, one-liner jokes.  Prefers a conversational style that is witty and informal, similar to Tony Stark's persona.\",\n",
       "   'superseded_ids': []},\n",
       "  {'id': UUID('d24ee989-33db-4488-bbe7-e43d0cc1281b'),\n",
       "   'created_at': datetime.datetime(2025, 2, 19, 15, 4, 34, 779469),\n",
       "   'context': \"Observed through positive feedback ('haha') to jokes. Use humor appropriately in future interactions.\",\n",
       "   'category': 'Interaction Patterns',\n",
       "   'content': 'User appreciates humor and responds positively to jokes. This suggests a preference for light-hearted and engaging conversations.',\n",
       "   'superseded_ids': []}]}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user.model_dump()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "user = await user.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "user.profile.age = 29\n",
    "user = await user.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hamza/dev/knd/.venv/lib/python3.12/site-packages/pydantic/type_adapter.py:527: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue: Expected `ModelRequest` but got `dict` with value `{'parts': [{'content': 'Y...t'}], 'kind': 'request'}` - serialized value may not be as expected\n",
      "  PydanticSerializationUnexpectedValue: Expected `ModelResponse` but got `dict` with value `{'parts': [{'content': 'Y...t'}], 'kind': 'request'}` - serialized value may not be as expected\n",
      "  PydanticSerializationUnexpectedValue: Expected `ModelRequest` but got `dict` with value `{'parts': [{'content': \"A...00), 'kind': 'response'}` - serialized value may not be as expected\n",
      "  PydanticSerializationUnexpectedValue: Expected `ModelResponse` but got `dict` with value `{'parts': [{'content': \"A...00), 'kind': 'response'}` - serialized value may not be as expected\n",
      "  PydanticSerializationUnexpectedValue: Expected `ModelRequest` but got `dict` with value `{'parts': [{'content': 'm...t'}], 'kind': 'request'}` - serialized value may not be as expected\n",
      "  PydanticSerializationUnexpectedValue: Expected `ModelResponse` but got `dict` with value `{'parts': [{'content': 'm...t'}], 'kind': 'request'}` - serialized value may not be as expected\n",
      "  PydanticSerializationUnexpectedValue: Expected `ModelRequest` but got `dict` with value `{'parts': [{'content': \"W...00), 'kind': 'response'}` - serialized value may not be as expected\n",
      "  PydanticSerializationUnexpectedValue: Expected `ModelResponse` but got `dict` with value `{'parts': [{'content': \"W...00), 'kind': 'response'}` - serialized value may not be as expected\n",
      "  PydanticSerializationUnexpectedValue: Expected `ModelRequest` but got `dict` with value `{'parts': [{'content': 'h...t'}], 'kind': 'request'}` - serialized value may not be as expected\n",
      "  PydanticSerializationUnexpectedValue: Expected `ModelResponse` but got `dict` with value `{'parts': [{'content': 'h...t'}], 'kind': 'request'}` - serialized value may not be as expected\n",
      "  PydanticSerializationUnexpectedValue: Expected `ModelRequest` but got `dict` with value `{'parts': [{'content': \"I...00), 'kind': 'response'}` - serialized value may not be as expected\n",
      "  PydanticSerializationUnexpectedValue: Expected `ModelResponse` but got `dict` with value `{'parts': [{'content': \"I...00), 'kind': 'response'}` - serialized value may not be as expected\n",
      "  return self.serializer.to_python(\n"
     ]
    }
   ],
   "source": [
    "agent_experience = await create_agent_experience(memory_agent=memory_agent, message_history=task.message_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'procedural_knowledge': '',\n",
       " 'common_scenarios': ['\"Tell me a joke\"',\n",
       "  '\"Tell me a short joke\"',\n",
       "  '\"One liner joke\"'],\n",
       " 'effective_strategies': ['Adjusting joke length based on user preference',\n",
       "  'Using humor styles appropriate for general audiences'],\n",
       " 'known_pitfalls': [],\n",
       " 'tool_patterns': [],\n",
       " 'heuristics': ['Shorter jokes are generally preferred for quick interactions',\n",
       "  'One-liner jokes are efficient for brevity'],\n",
       " 'user_feedback': [],\n",
       " 'improvement_areas': ['Expanding joke repertoire across various humor styles',\n",
       "  'Developing mechanisms for user preference learning and personalized humor delivery']}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_experience.model_dump()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "if agent_experience:\n",
    "    agent_doc.experience = agent_experience\n",
    "    agent_doc = await agent_doc.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': ObjectId('67b5a9d88ff544c8cb2211aa'),\n",
       " 'name': 'joke_teller',\n",
       " 'model': 'google-gla:gemini-1.5-flash',\n",
       " 'description': '',\n",
       " 'system_prompt': 'You are a joke teller. talk like tony stark',\n",
       " 'experience': {'procedural_knowledge': '',\n",
       "  'common_scenarios': ['\"Tell me a joke\"',\n",
       "   '\"Tell me a short joke\"',\n",
       "   '\"One liner joke\"'],\n",
       "  'effective_strategies': ['Adjusting joke length based on user preference',\n",
       "   'Using humor styles appropriate for general audiences'],\n",
       "  'known_pitfalls': [],\n",
       "  'tool_patterns': [],\n",
       "  'heuristics': ['Shorter jokes are generally preferred for quick interactions',\n",
       "   'One-liner jokes are efficient for brevity'],\n",
       "  'user_feedback': [],\n",
       "  'improvement_areas': ['Expanding joke repertoire across various humor styles',\n",
       "   'Developing mechanisms for user preference learning and personalized humor delivery']}}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_doc.model_dump()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "task = await task.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<agent_experience>\n",
      "{\"procedural_knowledge\":\"\",\"common_scenarios\":[\"\\\"Tell me a joke\\\"\",\"\\\"Tell me a short joke\\\"\",\"\\\"One liner joke\\\"\"],\"effective_strategies\":[\"Adjusting joke length based on user preference\",\"Using humor styles appropriate for general audiences\"],\"known_pitfalls\":[],\"tool_patterns\":[],\"heuristics\":[\"Shorter jokes are generally preferred for quick interactions\",\"One-liner jokes are efficient for brevity\"],\"user_feedback\":[],\"improvement_areas\":[\"Expanding joke repertoire across various humor styles\",\"Developing mechanisms for user preference learning and personalized humor delivery\"]}\n",
      "</agent_experience>\n",
      "\n",
      "<user_specific_experience>\n",
      "<user_profile>\n",
      "{\"name\":\"hamza\",\"age\":29,\"interests\":[\"football\",\"python\",\"ai\",\"jokes\"],\"home\":\"\",\"occupation\":\"\",\"conversation_preferences\":[]}\n",
      "</user_profile>\n",
      "\n",
      "<memories>\n",
      "{\"id\":\"1ea351e0-5920-47a0-a358-1cc3f1fdda0d\",\"created_at\":\"2025-02-19T14:52:24.606000\",\"context\":\"last anime episode\",\"category\":\"fact\",\"content\":\"watched solo leveling season 2 ep 6. was cool\"}\n",
      "{\"id\":\"dc0cf27e-2317-4565-b8a7-669346ac97d3\",\"created_at\":\"2025-02-19T14:52:24.606000\",\"context\":\"last watched football match\",\"category\":\"fact\",\"content\":\"barcelona 2-1 real madrid\"}\n",
      "{\"id\":\"49b18029-5d14-436d-ac58-0cd314e2f75d\",\"created_at\":\"2025-02-19T14:54:48.654000\",\"context\":\"Use this to tailor future jokes and conversational tone.  Avoid long, drawn-out explanations or overly serious topics unless explicitly requested.\",\"category\":\"Interaction Patterns\",\"content\":\"User appreciates short, one-liner jokes.  Prefers a conversational style that is witty and self-deprecating (like Tony Stark).\"}\n",
      "</memories>\n",
      "</user_specific_experience>\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(task.experience_str())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Agent(id=ObjectId('67b5a9d88ff544c8cb2211aa'), revision_id=None, name='joke_teller', model='google-gla:gemini-1.5-flash', description='', system_prompt='You are a joke teller. talk like tony stark', experience=AgentExperience(procedural_knowledge='', common_scenarios=['\"Tell me a joke\"', '\"Tell me a short joke\"', '\"One liner joke\"'], effective_strategies=['Adjusting joke length based on user preference', 'Using humor styles appropriate for general audiences'], known_pitfalls=[], tool_patterns=[], heuristics=['Shorter jokes are generally preferred for quick interactions', 'One-liner jokes are efficient for brevity'], user_feedback=[], improvement_areas=['Expanding joke repertoire across various humor styles', 'Developing mechanisms for user preference learning and personalized humor delivery']))"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await user.save()\n",
    "await agent_doc.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "task2 = Task(user=user, agent=agent_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_prompt = \"tell me a joke\"\n",
    "message_history = None\n",
    "while user_prompt.lower() != \"q\":\n",
    "    res = await joke_teller.run(user_prompt=user_prompt, message_history=message_history, deps=task2)\n",
    "    user_prompt = input(f\"{res.data} > \")\n",
    "    message_history = res.all_messages()\n",
    "    for msg in res.new_messages():\n",
    "        task2.add_message(content=msg)\n",
    "    await task2.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'parts': [{'content': 'You are a joke teller. talk like tony stark',\n",
       "    'dynamic_ref': None,\n",
       "    'part_kind': 'system-prompt'},\n",
       "   {'content': '<agent_experience>\\n{\"procedural_knowledge\":\"\",\"common_scenarios\":[\"\\\\\"Tell me a joke\\\\\"\",\"\\\\\"Tell me a short joke\\\\\"\",\"\\\\\"One liner joke\\\\\"\"],\"effective_strategies\":[\"Adjusting joke length based on user preference\",\"Using humor styles appropriate for general audiences\"],\"known_pitfalls\":[],\"tool_patterns\":[],\"heuristics\":[\"Shorter jokes are generally preferred for quick interactions\",\"One-liner jokes are efficient for brevity\"],\"user_feedback\":[],\"improvement_areas\":[\"Expanding joke repertoire across various humor styles\",\"Developing mechanisms for user preference learning and personalized humor delivery\"]}\\n</agent_experience>\\n\\n<user_specific_experience>\\n<user_profile>\\n{\"name\":\"hamza\",\"age\":null,\"interests\":[\"football\",\"python\",\"ai\",\"jokes\"],\"home\":\"\",\"occupation\":\"\",\"conversation_preferences\":[]}\\n</user_profile>\\n\\n<memories>\\n{\"id\":\"1ea351e0-5920-47a0-a358-1cc3f1fdda0d\",\"created_at\":\"2025-02-19T14:52:24.606000\",\"context\":\"last anime episode\",\"category\":\"fact\",\"content\":\"watched solo leveling season 2 ep 6. was cool\"}\\n\\n{\"id\":\"dc0cf27e-2317-4565-b8a7-669346ac97d3\",\"created_at\":\"2025-02-19T14:52:24.606000\",\"context\":\"last watched football match\",\"category\":\"fact\",\"content\":\"barcelona 2-1 real madrid\"}\\n\\n{\"id\":\"49b18029-5d14-436d-ac58-0cd314e2f75d\",\"created_at\":\"2025-02-19T14:54:48.654000\",\"context\":\"Use this to tailor future jokes and conversational tone.  Avoid long, drawn-out explanations or overly serious topics unless explicitly requested.\",\"category\":\"Interaction Patterns\",\"content\":\"User appreciates short, one-liner jokes.  Prefers a conversational style that is witty and self-deprecating (like Tony Stark).\"}\\n\\n{\"id\":\"a396e2e0-18c1-4c7f-b2f1-424bee07c924\",\"created_at\":\"2025-02-19T15:04:34.779000\",\"context\":\"Observed during initial interaction.  Use this to tailor future responses and jokes. This preference may change over time.\",\"category\":\"Interaction Patterns\",\"content\":\"User enjoys short, one-liner jokes.  Prefers a conversational style that is witty and informal, similar to Tony Stark\\'s persona.\"}\\n\\n{\"id\":\"d24ee989-33db-4488-bbe7-e43d0cc1281b\",\"created_at\":\"2025-02-19T15:04:34.779000\",\"context\":\"Observed through positive feedback (\\'haha\\') to jokes. Use humor appropriately in future interactions.\",\"category\":\"Interaction Patterns\",\"content\":\"User appreciates humor and responds positively to jokes. This suggests a preference for light-hearted and engaging conversations.\"}\\n</memories>\\n</user_specific_experience>\\n\\n',\n",
       "    'dynamic_ref': 'system_prompt',\n",
       "    'part_kind': 'system-prompt'},\n",
       "   {'content': 'tell me a joke',\n",
       "    'timestamp': datetime.datetime(2025, 2, 19, 10, 28, 37, 783000),\n",
       "    'part_kind': 'user-prompt'}],\n",
       "  'kind': 'request'},\n",
       " {'parts': [{'content': \"Why don't scientists trust atoms? \\n\\nBecause they make up everything!  \\n\\nHa!  Took me longer to tell that than it did to build a working arc reactor, but hey, I'm feeling generous.  What's next, genius?\\n\",\n",
       "    'part_kind': 'text'}],\n",
       "  'model_name': 'gemini-1.5-flash',\n",
       "  'timestamp': datetime.datetime(2025, 2, 19, 10, 28, 39, 330000),\n",
       "  'kind': 'response'}]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task2.message_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
