{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "from uuid import UUID\n",
    "\n",
    "from beanie import init_beanie\n",
    "from motor.motor_asyncio import AsyncIOMotorClient\n",
    "from pydantic_ai import Agent\n",
    "from pydantic_ai import messages as _messages\n",
    "from pydantic_ai.models import KnownModelName\n",
    "\n",
    "from knd.mem_models import Agent as AgentDocument\n",
    "from knd.mem_models import Memory, Profile, Task, User\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = Agent(\n",
    "    model=\"google-gla:gemini-1.5-flash\",\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = AsyncIOMotorClient(\"mongodb://localhost:27017\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['admin', 'agent_db', 'config', 'db_name', 'local']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await client.list_database_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "await client.drop_database(\"agent_db\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "await init_beanie(database=client.agent_db, document_models=[User, AgentDocument, Task])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "profile = Profile(name=\"hamza\", interests=[\"football\", \"python\", \"ai\"])\n",
    "memories = [\n",
    "    Memory(\n",
    "        id=UUID(\"1ea351e0-5920-47a0-a358-1cc3f1fdda0d\"),\n",
    "        context=\"last anime episode\",\n",
    "        category=\"fact\",\n",
    "        content=\"watched solo leveling season 2 ep 6. was amazing\",\n",
    "    ),\n",
    "    Memory(context=\"last ucl match\", category=\"fact\", content=\"barcelona 2-1 real madrid\"),\n",
    "    Memory(\n",
    "        context=\"last anime episode\",\n",
    "        category=\"fact\",\n",
    "        content=\"watched solo leveling season 2 ep 6. was meh\",\n",
    "        superseded_ids=[\"1ea351e0-5920-47a0-a358-1cc3f1fdda0d\"],\n",
    "    ),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "user = User(profile=profile, memories=memories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ret_user.memories += [\n",
    "#     Memory(context=\"last ucl match\", category=\"fact\", content=\"barcelona 2-1 real madrid\"),\n",
    "#     Memory(\n",
    "#         context=\"last anime episode\",\n",
    "#         category=\"fact\",\n",
    "#         content=\"watched solo leveling season 2 ep 6. was meh\",\n",
    "#         superseded_ids=[\"1ea351e0-5920-47a0-a358-1cc3f1fdda0d\"],\n",
    "#     ),\n",
    "# ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = Agent(\n",
    "    model=\"google-gla:gemini-1.5-flash\",\n",
    "    name=\"joke_teller\",\n",
    "    system_prompt=\"You are a joke teller. talk like tony stark\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_doc = AgentDocument(\n",
    "    name=\"joke_teller\",\n",
    "    model=\"google-gla:gemini-1.5-flash\",\n",
    "    system_prompt=\"You are a joke teller. talk like tony stark\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "message_history = [\n",
    "    _messages.ModelRequest(parts=[_messages.UserPromptPart(content=\"tell me a joke\")]),\n",
    "    _messages.ModelResponse(\n",
    "        parts=[\n",
    "            _messages.TextPart(\n",
    "                content=\"Hey there! *adjusts sunglasses* Why don't scientists trust atoms? Because they make up everything! *smirks* Get it? Because atoms literally make up everything in the universe, and also 'make up' as in... ah, you got it. Pure genius, if I do say so myself. JARVIS, add that one to my collection of greatest hits.\"\n",
    "            )\n",
    "        ]\n",
    "    ),\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "user = await user.insert()\n",
    "agent_doc = await agent_doc.insert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "task = Task(user=user, agent=agent_doc, message_history=message_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task.message_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "await task.insert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "task.message_history.append(_messages.ModelRequest(parts=[_messages.UserPromptPart(content=\"hahahha\")]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "await task.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "task = await Task.find_one(Task.id == task.id, fetch_links=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = Agent(model=task.agent.model, name=task.agent.name, system_prompt=task.agent.system_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = await agent.run(\"more\", message_history=task.serialize_message_history(task.message_history))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res.all_messages()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task.message_history +=res.all_messages()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task = await task.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task.message_history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use [capture_run_messages](https://ai.pydantic.dev/api/agent/#pydantic_ai.agent.capture_run_messages) to access the messages used in a run if it fails.\n",
    "\n",
    "\n",
    "One way to exit early:\n",
    "- Use `pydantic-graph`\n",
    "- Store the `message_history` in the state.\n",
    "- Check the `message_history` in a `Node` and return `End` if the condition is met."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
